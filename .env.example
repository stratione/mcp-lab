# MCP DevOps Lab — Environment Configuration
# ============================================
# This file is SCREEN-SAFE — no secrets here!
# API keys live in .env.secrets (never share that file).
#
# Quick start:
#   cp .env.example .env
#   cp .env.secrets.example .env.secrets
#   # edit .env.secrets with your API keys (optional — Ollama works without keys)

# Gitea token (generated by bootstrap, paste here after first run)
GITEA_TOKEN=your-gitea-token-here

# ──── MCP Feature Switches ────────────────────────────
# Flip these during the workshop to progressively enable tools
USER_MCP_ENABLED=false
GITEA_MCP_ENABLED=false
REGISTRY_MCP_ENABLED=false
PROMOTION_MCP_ENABLED=false

# ──── LLM Provider Defaults ───────────────────────────
# Options: ollama, openai, anthropic, google
LLM_PROVIDER=ollama
LLM_MODEL=llama3.1:8b

# Ollama URL (default works for Docker Desktop on Mac/Windows)
# For Podman on macOS, use: http://host.containers.internal:11434
# For Linux, use: http://172.17.0.1:11434
OLLAMA_URL=http://host.docker.internal:11434
