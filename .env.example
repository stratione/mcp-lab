# MCP DevOps Lab — Environment Configuration
# ============================================
# This file is SCREEN-SAFE — no secrets here!
# API keys live in .env.secrets (never share that file).
#
# Quick start:
#   cp .env.example .env
#   cp .env.secrets.example .env.secrets
#   # edit .env.secrets with your API keys (optional — Ollama works without keys)

# ──── MCP Server Profiles ─────────────────────────────
# Controls which MCP servers start with 'docker compose up -d' (or 'podman compose')
# Add profiles as comma-separated values:
#   user       → +6 user tools (port 8003)
#   gitea      → +7 git/repo tools (port 8004)
#   registry   → +3 registry tools (port 8005)
#   promotion  → +3 promotion tools (port 8006)
# Examples:
#   COMPOSE_PROFILES=                              # no MCP servers (default)
#   COMPOSE_PROFILES=user                          # user tools only
#   COMPOSE_PROFILES=user,gitea,registry,promotion # all 19 tools
COMPOSE_PROFILES=

# Gitea token (generated by bootstrap, paste here after first run)
GITEA_TOKEN=your-gitea-token-here

# ──── LLM Provider Defaults ───────────────────────────
# Options: ollama, openai, anthropic, google
LLM_PROVIDER=ollama
LLM_MODEL=llama3.1:8b

# Ollama URL — choose the right one for your setup:
#   Docker Desktop (Mac/Windows): http://host.docker.internal:11434  (default)
#   Podman on macOS:              http://host.containers.internal:11434
#   Linux (native Docker):        http://172.17.0.1:11434
OLLAMA_URL=http://host.docker.internal:11434
