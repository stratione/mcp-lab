# MCP DevOps Lab â€” Environment Configuration

# Gitea token (generated by bootstrap, paste here after first run)
GITEA_TOKEN=your-gitea-token-here

# Feature switches (set to true to enable MCP tools for each system)
GITEA_MCP_ENABLED=false
REGISTRY_MCP_ENABLED=false
PROMOTION_MCP_ENABLED=false

# LLM Provider defaults for Chat UI
# Options: ollama, openai, anthropic, google
LLM_PROVIDER=ollama
LLM_API_KEY=your-api-key-here
LLM_MODEL=llama3.1:8b

# Ollama URL (default works for Docker Desktop on Mac/Windows)
# For Linux, use: http://172.17.0.1:11434
OLLAMA_URL=http://host.docker.internal:11434
