# MCP DevOps Lab — Environment Configuration
# ============================================
# This file is SCREEN-SAFE — no secrets here!
# API keys live in .env.secrets (never share that file).
#
# Quick start:
#   ./scripts/1-setup.sh
#   # .env and .env.secrets are created automatically on first run.
#   # Edit .env.secrets to add cloud LLM API keys (optional — Ollama works without them).

# ──── MCP Server Profiles ─────────────────────────────
# Controls which MCP servers start with 'docker compose up -d' (or 'podman compose')
# Add profiles as comma-separated values:
#   user       → +6 user tools (port 8003)
#   gitea      → +7 git/repo tools (port 8004)
#   registry   → +3 registry tools (port 8005)
#   promotion  → +3 promotion tools (port 8006)
# Examples:
#   COMPOSE_PROFILES=                              # no MCP servers (default)
#   COMPOSE_PROFILES=user                          # user tools only
#   COMPOSE_PROFILES=user,gitea,registry,promotion # all 19 tools
COMPOSE_PROFILES=

# Gitea token (generated by bootstrap, paste here after first run)
GITEA_TOKEN=your-gitea-token-here

# ──── LLM Provider Defaults ───────────────────────────
# Options: ollama, openai, anthropic, google
LLM_PROVIDER=ollama
LLM_MODEL=llama3.1:8b

# Ollama URL — choose the right one for your setup:
#   Docker Desktop (Mac/Windows): http://host.docker.internal:11434  (default)
#   Podman on macOS:              http://host.containers.internal:11434
#   Linux (native Docker):        http://172.17.0.1:11434
OLLAMA_URL=http://host.docker.internal:11434

# Container engine (auto-detected by setup script)
CONTAINER_ENGINE=docker

# ──── Optional: MCP server controls in the Chat UI ────────────────────────
# Set to "true" to show Start/Stop buttons for each MCP server inside the UI.
# Requires /var/run/docker.sock to be mounted (see docker-compose.yml).
# Leave as "false" (default) if you don't want the UI touching containers.
ENABLE_MCP_CONTROLS=false
